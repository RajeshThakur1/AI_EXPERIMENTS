{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the packages\n",
    "!pip install git+https://github.com/huggingface/diffusers.git\n",
    "!pip install transformers sentencepiece accelerate protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "import diffusers\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the rope function to handle CUDA device\n",
    "_flux_rope = diffusers.models.transformers.transformer_flux.rope\n",
    "def new_flux_rope(pos: torch.Tensor, dim: int, theta: int) -> torch.Tensor:\n",
    "    assert dim % 2 == 0, \"The dimension must be even.\"\n",
    "    if pos.device.type == \"cuda\":\n",
    "        # Move tensor to CPU for ROPE computation, then move it back to CUDA\n",
    "        return _flux_rope(pos.to(\"cpu\"), dim, theta).to(device=pos.device)\n",
    "    else:\n",
    "        # Perform ROPE computation directly if tensor is not on CUDA\n",
    "        return _flux_rope(pos, dim, theta)\n",
    "diffusers.models.transformers.transformer_flux.rope = new_flux_rope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Flux Schnell model\n",
    "pipe = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-schnell\",\n",
    "    revision='refs/pr/1',\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "# This is the textual description that the model will use to generate the image\n",
    "import base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "# Modify the rope function to handle CUDA device\n",
    "encode_image = encode_image(\"gen_image.png\")\n",
    "prompt = f\"{encode_image} can you make\"\n",
    "\n",
    "# Generate the image\n",
    "out = pipe(\n",
    "    prompt=prompt,\n",
    "    guidance_scale=0.,\n",
    "    height=1024,\n",
    "    width=1024,\n",
    "    num_inference_steps=4,\n",
    "    max_sequence_length=256,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated image\n",
    "out.save(\"gen_image.png\")\n",
    "\n",
    "# Display the generated image\n",
    "image = Image.open(\"gen_image.png\")\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
